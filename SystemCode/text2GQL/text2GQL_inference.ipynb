{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "PLP PM - Conversational natural language query of relational and non-relational databases.\n",
        "\n",
        "Notebook for text2GQL inference"
      ],
      "metadata": {
        "id": "cjpK2B5MGBbm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64p2Ajc4EyQw"
      },
      "source": [
        "# Load Graph DB"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load modules"
      ],
      "metadata": {
        "id": "ZFpr5V3dFbsd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WyPvzOF0-uF"
      },
      "outputs": [],
      "source": [
        "#!pip install neo4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0jD2k_51GMF",
        "outputId": "4e693a07-62bf-4199-ed31-25abd21ac3b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.4.0\n"
          ]
        }
      ],
      "source": [
        "from neo4j import GraphDatabase\n",
        "from neo4j.exceptions import ServiceUnavailable\n",
        "import logging\n",
        "import spacy\n",
        "print(spacy.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsCkvx3PEyQz"
      },
      "source": [
        "## Connect to DB"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will need to serve the Neo4j graph DB first (e.g. using Neo4j desktop), then connect the notebook to the DB as follows:"
      ],
      "metadata": {
        "id": "ouHjDGOsE7Xn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr0wG6dx2fTE"
      },
      "outputs": [],
      "source": [
        "graph = GraphDatabase.driver(\n",
        "    \"neo4j://localhost:7687\",\n",
        "    auth=(\"neo4j\", \"password\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_P9u0KP3IIp"
      },
      "outputs": [],
      "source": [
        "#reset DB\n",
        "\n",
        "query = (\n",
        "        \"MATCH (all_nodes)\"\n",
        "        \"OPTIONAL MATCH (all_nodes)-[all_rels]->()\"\n",
        "        \"DELETE all_nodes, all_rels\"\n",
        "    )\n",
        "with graph.session() as session:\n",
        "    result = session.run(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB04vNkpEyQ0"
      },
      "source": [
        "## Insert data into DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_C7LqMS1aAQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(r'QArelview 26Oct v2.xlsx')\n",
        "#print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-_yN0au1cHZ",
        "outputId": "c6514018-4b96-4e7d-ec8a-13f6868eb998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Sentence': 'IRANIAN SUPPORT \\nIsrael sees an outside catalyst for the violence - Iran, which both Hamas and its sometime ally Islamic Jihad say has pledged unlimited assistance for them as the Syrian civil war, where Tehran deployed reinforcements for Damascus, winds down. \\n', 'Question': 'What did Tehran deploy reinforcements for?', 'Relation': 'twinned administrative body', 'Headspan': 'Tehran', 'Tailspan': 'Damascus'}\n"
          ]
        }
      ],
      "source": [
        "df = df[df.Remove != 1]\n",
        "df = df.reset_index()\n",
        "QArel = []\n",
        "for index, row in df.iterrows():\n",
        "    QArel.append({'Sentence':row['Sentence'],'Question': row['Question'],'Relation': row['Relation'],'Headspan': row['Headspan'],'Tailspan': row['Tailspan']})\n",
        "print(QArel[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmE80N4Z1hYs"
      },
      "outputs": [],
      "source": [
        "# Selected relation classes\n",
        "\n",
        "topkrel = ['founded by', 'inception', 'parent organization', 'employer',  'headquarters location',  'located in the administrative territorial entity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tysxocjN1mQJ"
      },
      "outputs": [],
      "source": [
        "for i,v in enumerate(QArel):\n",
        "    if i>=0 and (v['Relation'] in topkrel):\n",
        "        query = (\n",
        "                \"MERGE (node: Entity {name: $name})\"\n",
        "                \"RETURN node\"\n",
        "            )\n",
        "        with graph.session() as session:\n",
        "            result = session.run(query, name=v['Headspan'])\n",
        "\n",
        "        query = (\n",
        "                \"MERGE (node: Entity {name: $name})\"\n",
        "                \"RETURN node\"\n",
        "            )\n",
        "        with graph.session() as session:\n",
        "            result = session.run(query, name=v['Tailspan'])\n",
        "\n",
        "        query = (\n",
        "                \"MATCH (n1:Entity {name: $name1})\"\n",
        "                \"MATCH (n2:Entity {name: $name2})\"\n",
        "                \"MERGE (n1) - [r: \"+v['Relation'].replace(' ','_')+\" ] -> (n2)\"\n",
        "                \"RETURN n1, n2, r\"\n",
        "            )\n",
        "        with graph.session() as session:\n",
        "            result = session.run(query, name1=v['Headspan'], name2=v['Tailspan'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYAn248zEyQ1"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nipKKFzYEyQ1"
      },
      "source": [
        "## Load modules and model files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRiM6QU2EyQ1"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow==2.6.0\n",
        "#!pip install keras==2.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TfIZSXQEyQ1"
      },
      "outputs": [],
      "source": [
        "#!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuYqVOsHEyQ2",
        "outputId": "50eed6d5-19e5-4a82-d70c-4188d254fd47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.6.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oY9tIunEyQ2"
      },
      "outputs": [],
      "source": [
        "gql_model = keras.models.load_model(\"gqlmodel.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvLsT0FJEyQ2",
        "outputId": "fdb066a6-688e-4138-f0ea-efd6f4cf730d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Gerard\\anaconda3\\envs\\issenv\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "with open('enc_class.pkl','rb') as f:\n",
        "    enc_class = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoT-ZXOdEyQ2",
        "outputId": "a6df5506-0c61-4f06-a88d-5005c60f862b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel, pipeline\n",
        "\n",
        "model = AutoModel.from_pretrained('bert-base-uncased')\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "fe = pipeline('feature-extraction', model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryvxDE_NEyQ2"
      },
      "source": [
        "## Input Question and run inference"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input natural language question"
      ],
      "metadata": {
        "id": "Wl11qrzqF1R4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZTWW1QOEyQ3"
      },
      "outputs": [],
      "source": [
        "# input_question = ['When was Facebook founded?']\n",
        "# input_question = ['What company does Google belong to?']\n",
        "# input_question = ['Who is the founder of Tesla?']\n",
        "\n",
        "maxlen = [50,768]\n",
        "input_vec = np.zeros([1,maxlen[0],maxlen[1]])\n",
        "features = fe(input_question)\n",
        "features = np.squeeze(features)\n",
        "input_vec[0,0:features.shape[0],:] = features"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraction of Node1 and prediction of relation"
      ],
      "metadata": {
        "id": "2POzOxj0FqHG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttLpx3UlEyQ3",
        "outputId": "14eea13d-4661-46e0-ba84-7589bc078fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tesla\n",
            "founded by\n"
          ]
        }
      ],
      "source": [
        "ques_ent = nlp(input_question[0])\n",
        "ent_pred = ques_ent.ents[0].text\n",
        "print(ent_pred)\n",
        "\n",
        "y_prediction = gql_model.predict(input_vec)\n",
        "y_prediction = np.argmax(y_prediction, axis = 1)\n",
        "rel_pred = enc_class.classes_[y_prediction[0]]\n",
        "print(rel_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph query for Node2 as answer"
      ],
      "metadata": {
        "id": "CZ0C2aU3Fv2l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wq9lU9oWEyQ3",
        "outputId": "bf57def8-042c-4839-83af-338f478c66f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elon Musk\n"
          ]
        }
      ],
      "source": [
        "query = (\n",
        "        \"MATCH (n1:Entity {name: $ent1})-[rel:\"+rel_pred.replace(\" \",\"_\")+\"] -> (n2:Entity)\"\n",
        "        \"RETURN n1, n2, rel\"\n",
        "    )\n",
        "with graph.session() as session:\n",
        "    results = session.run(query, ent1=ent_pred)\n",
        "    for result in results:\n",
        "        answer = result['n2']['name']\n",
        "        print(answer)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZFpr5V3dFbsd",
        "qsCkvx3PEyQz",
        "kB04vNkpEyQ0",
        "nipKKFzYEyQ1",
        "ryvxDE_NEyQ2"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}